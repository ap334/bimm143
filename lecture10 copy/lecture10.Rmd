---
title: "lecture10"
author: "Anastasia Pimentel"
date: "2/6/2020"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
##Unsupervised Learning Analysis of Human Breast Cancer Cells
Importing our data from University of Wisconsion Medical Center.
```{r}
wisc.df <- read.csv("WisconsinCancer.csv")


```
Viewing the data:
```{r}
View(wisc.df)
head(wisc.df)
tail(wisc.df)
```
The data has a weird empty X column! Let's clean this up and get rid of it. 
Convert columns data 3-32 to a matrix. We don't include the frist two columns because they aren't directly related to the biopsy data. 
```{r}
wisc.data <- as.matrix(wisc.df[,3:32])

```

How many patients are in the matrix?
```{r}
nrow(wisc.data)
```



How many malignet vs benign diagnosis were there? 
```{r}
diagnosis <- wisc.df$diagnosis
table(diagnosis)
```


How many column names are the mean of something?
```{r}
length(grep("_mean", colnames(wisc.data), value=TRUE))

```


Now we can see if we need to scale our data in the PCA.
```{r}
round(apply(wisc.data, 2, sd), 2)
```
Since the SDs are so different, these must be in different scales. So, we'll need to scale. 

PCA time!
```{r}
wisc.pr <- prcomp(wisc.data, scale=TRUE)
summary(wisc.pr)
```

So, PC1 captures 44.27% of the original varience. We need 3 PCs to cover at least 70% of the original variance. 7 PCs are needed for at least 90% of the original variance.
Now we need to find the PCA elbow:

```{r}
biplot(wisc.pr)
```
A hot mess! We need a better way to graph this. 


Let's take a closer look at what we have.
```{r}
attributes(wisc.pr)
```
```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=diagnosis)
abline(h=0, col="grey", lty=2)
abline(v=0, col="grey", lty=2)
```

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,3], col=diagnosis)
abline(h=0, col="grey", lty=2)
abline(v=0, col="grey", lty=2)
```

```{r}
hc <- hclust(dist(wisc.data))
plot(hc)
```

Totally unclear! The raw data is too confusing. 

```{r}
wisc.pr.hclust <- hclust(dist(wisc.pr$x[,1:3]), method="ward.D2")
plot(wisc.pr.hclust)
abline(h=50, col="grey", lty=2)
cutree(wisc.pr.hclust, k=50)
```


Lets get our clusters out of the tree.
```{r}
grps3 <- cutree(wisc.pr.hclust, k=3)
table(grps3)
```

This is how many people are in each cluster.

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=grps3)
```
So what color means what?
```{r}
table(grps3, wisc.df$diagnosis)
```


xxxxxxxxxxxxxxxxxxxxxxxxxx



```{r}
pr.var <- wisc.pr$sdev^2

pve <- wisc.pr$x/pr.var


plot(pve)
```


xxxxxxxxxxxxxxxxxxxxxxxxxxx

Open new data and use predict function with our previous PCA model and new data. 
```{r}
new <- read.csv("new_samples.csv")
new

npc <- predict(wisc.pr, newdata = new)
npc

plot(wisc.pr$x[,1], wisc.pr$x[,2], col=wisc.df$diagnosis)
points(npc[,1], npc[,2], col="blue", pch=15, cex=3)
text(npc[,1], npc[,2], labels=c(1,2), col="white")
```



















